# üîß Guide Technique - Architecture Blend AI + OpenAI

## Vue d'ensemble

VoiceCheck AI utilise une architecture en 3 √©tapes pour v√©rifier les contacts :

1. **Blend AI** : G√®re les appels t√©l√©phoniques et la conversation vocale
2. **Transcript** : R√©cup√©ration de l'enregistrement de la conversation
3. **OpenAI GPT-3.5** : Analyse du transcript pour extraire consentement et identit√©

---

## üéØ Flow complet d'un appel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  VoiceCheck AI  ‚îÇ
‚îÇ   (Streamlit)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 1. Initier appel
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Blend AI API  ‚îÇ ‚óÑ‚îÄ‚îÄ Prompt personnalis√© avec:
‚îÇ   /v1/calls     ‚îÇ     - Demande consentement RGPD
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     - V√©rification identit√©
         ‚îÇ
         ‚îÇ 2. Appel t√©l√©phonique
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Contact      ‚îÇ
‚îÇ  (t√©l√©phone)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ 3. Conversation enregistr√©e
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Blend AI API   ‚îÇ
‚îÇ  Transcript     ‚îÇ ‚óÑ‚îÄ‚îÄ Polling toutes les 5s
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     jusqu'√† "completed"
         ‚îÇ
         ‚îÇ 4. Transcript texte
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OpenAI GPT-3.5 ‚îÇ
‚îÇ   Analyse NLP   ‚îÇ ‚óÑ‚îÄ‚îÄ Extraction:
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     - consent: true/false
         ‚îÇ              - identity_confirmed: true/false
         ‚îÇ
         ‚îÇ 5. R√©sultat structur√©
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   results.json  ‚îÇ
‚îÇ   (Database)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã D√©tails des services

### 1. BlendService (`services/twilio_service.py`)

**M√©thode `make_call()`**
```python
def make_call(self, to_number: str, contact_id: str, task_prompt: str, ...) -> Dict
```

Envoie une requ√™te POST √† `https://api.bland.ai/v1/calls` avec :

**Payload envoy√©e :**
```json
{
  "phone_number": "+33695550023",
  "voice": "429bae88-a95f-4dd3-bc9e-d6c2c3a51efa",
  "record": true,
  "max_duration": 12,
  "language": "fr",
  "task": "<prompt_personnalis√©>",
  "first_sentence": "Bonjour, je suis une assistante virtuelle...",
  "metadata": {
    "contact_id": "123"
  }
}
```

**R√©ponse Blend AI :**
```json
{
  "call_id": "abc-123-def",
  "status": "queued"
}
```

---

**M√©thode `fetch_call_result(call_id)`**

Envoie GET √† `https://api.bland.ai/v1/calls/{call_id}` pour r√©cup√©rer le statut et le transcript.

**R√©ponse (appel termin√©) :**
```json
{
  "call_id": "abc-123-def",
  "status": "completed",
  "duration": 78,
  "transcript": "Assistant: Bonjour, je suis une assistante virtuelle...\nPerson: Oui j'accepte...",
  "recording_url": "https://...",
  "metadata": {
    "contact_id": "123"
  }
}
```

---

**M√©thode `build_task_prompt(nom, prenom)`**

Construit le prompt d√©taill√© pour Blend AI qui guide la conversation :

```text
Objectif: V√©rifier les coordonn√©es d'un contact...

Flux de l'appel:
1. INTRODUCTION
   - Pr√©sentez-vous: "Bonjour, je suis une assistante virtuelle..."
   
2. CONSENTEMENT RGPD (OBLIGATOIRE)
   - Demandez: "Conform√©ment au RGPD, acceptez-vous de poursuivre..."
   - Si OUI: Passez √† l'√©tape 3
   - Si NON: Terminez poliment
   
3. V√âRIFICATION D'IDENTIT√â
   - Posez: "Confirmez-vous √™tre {prenom} {nom}?"
   - Si OUI: Remerciez et terminez
   - Si NON: Notez et terminez
```

Ce prompt guide l'IA de Blend pour avoir une conversation naturelle tout en suivant le flow requis.

---

### 2. OpenAIService (`services/openai_service.py`)

**M√©thode `analyze_consent_and_identity()`**

Envoie le transcript complet √† OpenAI GPT-3.5 pour extraire les informations critiques.

**Prompt syst√®me :**
```text
Tu es un assistant d'analyse de conversations t√©l√©phoniques pour la conformit√© RGPD.
Ton r√¥le est d'analyser le transcript et d'extraire:

1. CONSENTEMENT RGPD: accept√©/refus√©/pas clair?
2. CONFIRMATION D'IDENTIT√â: confirm√©/refus√©/pas clair?

R√©ponds UNIQUEMENT en JSON:
{
  "consent": true/false/null,
  "identity_confirmed": true/false/null,
  "reasoning": "explication"
}
```

**Exemple de transcript analys√© :**
```
Assistant: Bonjour, je suis une assistante virtuelle de VoiceCheck AI.
Assistant: Conform√©ment au RGPD, acceptez-vous de poursuivre cet √©change?
Person: Oui, d'accord.
Assistant: Merci. Confirmez-vous √™tre Jean Dupont?
Person: Oui, c'est bien moi.
Assistant: Parfait, merci. Au revoir.
```

**R√©ponse OpenAI :**
```json
{
  "consent": true,
  "identity_confirmed": true,
  "reasoning": "La personne a clairement accept√© le consentement RGPD et confirm√© son identit√©"
}
```

---

## üîÑ Impl√©mentation dans app.py

### Mode MOCK (par d√©faut)

```python
if is_mock:
    # Simulation instantan√©e
    call_sid = twilio_service.make_call(...)
    consent_result = twilio_service.simulate_consent_response()
    identity_result = twilio_service.simulate_identity_confirmation()
    # Pas d'appel r√©el, r√©sultats al√©atoires
```

### Mode R√âEL (avec cl√©s API)

```python
else:
    # 1. Construire le prompt
    task_prompt = twilio_service.build_task_prompt(nom, prenom)
    
    # 2. Initier l'appel Blend
    call_response = twilio_service.make_call(
        to_number=telephone,
        contact_id=contact_id,
        task_prompt=task_prompt,
        language="fr"
    )
    call_id = call_response['call_id']
    
    # 3. Polling: attendre que l'appel se termine
    while attempt < 60:  # Max 5 minutes
        time.sleep(5)
        call_status = twilio_service.fetch_call_result(call_id)
        
        if call_status['status'] == 'completed':
            transcript = call_status['transcript']
            break
    
    # 4. Analyser avec OpenAI
    analysis = openai_service.analyze_consent_and_identity(
        transcript=transcript,
        nom=nom,
        prenom=prenom
    )
    
    # 5. Sauvegarder dans results.json
    result = {
        'contact_id': contact_id,
        'consent': analysis['consent'],
        'identity_confirmed': analysis['identity_confirmed'],
        'transcription': transcript,
        'reasoning': analysis['reasoning']
    }
    db.save_result(result)
```

---

## ‚öôÔ∏è Configuration requise

### Mode MOCK
```bash
USE_MOCK_SERVICES=True
# Aucune cl√© API n√©cessaire
```

### Mode R√âEL
```bash
USE_MOCK_SERVICES=False
BLEND_API_KEY=your_blend_api_key_here
BLEND_ENDPOINT=https://api.bland.ai/v1/calls
OPENAI_API_KEY=sk-proj-...
```

**Obtention des cl√©s :**
- Blend AI : https://app.bland.ai ‚Üí Settings ‚Üí API Keys
- OpenAI : https://platform.openai.com ‚Üí API Keys

---

## üìä Structure des donn√©es

### Contact (contacts.json)
```json
{
  "id": "1",
  "nom": "Dupont",
  "prenom": "Jean",
  "telephone": "+33612345678",
  "status": "pending",
  "created_at": "2024-11-13T10:30:00"
}
```

### R√©sultat (results.json)
```json
{
  "contact_id": "1",
  "nom": "Dupont",
  "prenom": "Jean",
  "telephone": "+33612345678",
  "call_sid": "blend-call-abc123",
  "consent": true,
  "identity_confirmed": true,
  "no_response": false,
  "transcription": "Assistant: Bonjour...\nPerson: Oui...",
  "reasoning": "Consentement et identit√© confirm√©s",
  "timestamp": "2024-11-13T10:35:42"
}
```

---

## üêõ Debugging

### V√©rifier le mode actif
```python
from utils.config import Config
print(f"Mode mock: {Config.is_mock_mode()}")
print(f"Blend API Key: {Config.BLEND_API_KEY[:10]}..." if Config.BLEND_API_KEY else "Non d√©fini")
```

### Tester l'appel Blend manuellement
```python
from services.twilio_service import BlendService

blend = BlendService()
response = blend.make_call(
    to_number="+33612345678",
    contact_id="test",
    task_prompt="Test simple",
    first_sentence="Bonjour, ceci est un test"
)
print(response)
```

### Tester l'analyse OpenAI
```python
from services.openai_service import OpenAIService

openai_svc = OpenAIService()
result = openai_svc.analyze_consent_and_identity(
    transcript="Person: Oui j'accepte. Person: Oui c'est moi.",
    nom="Dupont",
    prenom="Jean"
)
print(result)
```

---

## ‚ö†Ô∏è Limitations et consid√©rations

### Temps d'attente
- L'appel Blend peut durer de 30 secondes √† 2-3 minutes
- Le polling attend jusqu'√† 5 minutes maximum
- Pendant ce temps, l'interface Streamlit affiche "‚è≥ Appel en cours..."

### Co√ªts
- **Blend AI** : ~0.09$/minute d'appel
- **OpenAI GPT-3.5** : ~0.002$ par analyse (200 tokens)
- Budget estim√© : ~0.10-0.15$ par appel complet

### Gestion des erreurs
- Si Blend ne r√©pond pas : `no_response = True`
- Si le transcript est vide : `consent = None, identity_confirmed = None`
- Si OpenAI √©choue : le raisonnement contient l'erreur

### RGPD
- Le consentement est explicitement demand√© en d√©but d'appel
- Les enregistrements sont stock√©s localement (data/results.json)
- Les transcripts complets sont sauvegard√©s pour audit

---

## üöÄ Prochaines am√©liorations possibles

1. **Webhook** : Utiliser les webhooks Blend au lieu du polling
2. **Async** : Traiter plusieurs appels en parall√®le
3. **Retry** : Gestion des appels √©chou√©s avec retry automatique
4. **Dashboard temps r√©el** : WebSocket pour mise √† jour live
5. **Export audio** : T√©l√©charger les enregistrements audio
6. **Analyse avanc√©e** : D√©tection du sentiment, de la satisfaction client

---

## üìû Support

Pour toute question technique :
- Documentation Blend AI : https://docs.bland.ai
- Documentation OpenAI : https://platform.openai.com/docs
- Code source : Voir les fichiers `services/` et `app.py`
